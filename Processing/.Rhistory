centMGM <- centralityTable(GraphMGMCENT,standardized = FALSE, signed = FALSE)
#CentralityPlot Total
centrality_table = centralityPlot(GraphMGMCENT, include = c("Strength"), scale = "raw",
orderBy = "Strength", signed = FALSE) + theme_nice() + theme(axis.text.y=element_text(hjust=1))
ggsave(here("Output", "Centrality_Table.jpg"), centrality_table)
#Convert to igraph
igraph_graph <- graph.adjacency(FitW3$pairwise$wadj, mode="undirected", weighted = TRUE)
#Degree centrality
degree_cent = degree(igraph_graph)
#Merge vectors
degree_data <- data.frame(names(W3), degree_cent)
#Shortest Path Lenght
SPLMGM <- centrality(GraphMGM)$ShortestPathLengths
SPLMGM <- SPLMGM[upper.tri(SPLMGM)]
#Average shortest path length
ASPL_MGM <- mean(SPLMGM)
#Check with another function (this is unweighted ASPL)
splmgm = shortest.paths(igraph_graph)
splmgm <- splmgm[upper.tri(splmgm)]
aspl_mgm <- mean(splmgm)
#and with tnet from opshal
spl_o = distance_w(FitW3$pairwise$wadj, directed=NULL, subsample=1)
spl_o <- spl_o[upper.tri(spl_o)]
aspl_o <- mean(spl_o)
#edge weight accuracy: non parametric bootstrap with 8 cores
#edgeacc =  bootnet(W3, nBoots = 1000, nCores = 8, 'mgm')
#load the object instead:
edgeacc = readRDS(here("Input", "edgeacc.rds"))
#plot 1
pdf('../Output/robustness/edge_accuracy.pdf', height = 70, width = 50)
plot(edgeacc, labels = longnames, order = "sample")
dev.off()
#Plot 2
pdf('../Output/robustness/edge_accuracy_CI.pdf', height = 70, width = 50)
plot(edgeacc, plot = "interval", split0 = TRUE, order="sample", labels=longnames)
dev.off()
#summary
saummary_edgeacc = summary(edgeacc, statistics = c("edge", "strength"),
perNode = FALSE, rank = FALSE)
# case dropping bootstrap
#centstab = bootnet(W3, nBoots = 1000, 'mgm', type = "case", nCores = 8)
#load the object instead:
centstab = readRDS(here("Input", "centstab.rds"))
#plot 1
pdf('../Output/robustness/Centrality_stability.pdf', height = 70, width = 50)
plot(centstab, "Strength", perNode = TRUE, labels = longnames,
subsetRange = c(100,50))
dev.off()
#Plot 2
pdf('../Output/robustness/Centrality_stability_CI.pdf', height = 70, width = 50)
plot(centstab, "Strength", CIstyle =  "quantiles")
dev.off()
#CS-coefficient (result should be above 0.25, better if above 0.5)
corstab = corStability(centstab)
corstab
# Test: difference of weight ties 2-3 vs 4-5
differenceTest(edgeacc, 2--3, 3--4, "strength")
# Plot test results for every edge weight in the network
pdf('../Output/robustness/test_edges.pdf', height = 70, width = 50)
plot(edgeacc, "edge", plot = "difference", onlyNonZero = TRUE, order = "sample",
labels = T)
dev.off()
# Test: difference of strength of node 5 [conspiracy] vs 20 [hesitancy] (if the bootstrapped CI include 0, they do not differ)
test_conspiracy_vs_hesitancy = differenceTest(edgeacc, 5, 20, "strength")
# Plot test results for every edge weight in the network
pdf('../Output/robustness/test_strenghts.pdf', height = 70, width = 50)
plot(edgeacc, "strength", order = "mean", labels = T)
dev.off()
#small world network
W3_small_core = smallworldness(FitW3$pairwise$wadj, B = 1000)
W3_small_core
#model selection
backbone.suggest(FitW3$pairwise$wadj)
# application of the disparity filter
backbone_matrix <- disparity(
inputGraphMGM,
alpha = 0.05,
signed = FALSE,
mtc = "none",
class = "original",
narrative = TRUE)
#plot
set.seed(100)
GraphMGM<-qgraph(backbone_matrix,
layout = "spring", theme = "Borkulo",
labels = shortnames,nodeNames = longnames,
details = FALSE, vsize=6.0, shape = shapes,
groups=Totalgroup_comm, color= Totalgroup_cols,
legend = TRUE, legend.cex = 0.35, borders = FALSE,
filetype="jpg", filename=here("Output", "backbone.jpg"))
#Fitting logistic regressions
model_vac_bad <- glm( hesitancy ~ vac_bad + sex + age + educ + reg + eco_insec,
data = W3, family = binomial)
model_vac_ob <- glm( hesitancy ~ vac_ob + sex + age + educ + reg + eco_insec,
data = W3, family = binomial)
model_worry <- glm( hesitancy ~ worry + sex + age + educ + reg + eco_insec,
data = W3, family = binomial)
model_risk <- glm( hesitancy ~ risk + sex + age + educ + reg + eco_insec,
data = W3, family = binomial)
model_conspiracy <- glm( hesitancy ~ conspiracy + sex + age + educ + reg + eco_insec,
data = W3, family = binomial)
model_nat <- glm( hesitancy ~ nat + sex + age + educ + reg + eco_insec,
data = W3, family = binomial)
model_h_locus <- glm( hesitancy ~ h_locus + sex + age + educ + reg + eco_insec,
data = W3, family = binomial)
model_he_eco <- glm( hesitancy ~ he_eco + sex + age + educ + reg + eco_insec,
data = W3, family = binomial)
model_PTV_L <- glm( hesitancy ~ PTV_L + sex + age + educ + reg + eco_insec,
data = W3, family = binomial)
model_PTV_5SM <- glm( hesitancy ~ PTV_5SM + sex + age + educ + reg + eco_insec,
data = W3, family = binomial)
model_PTV_BOI <- glm( hesitancy ~ PTV_BOI + sex + age + educ + reg + eco_insec,
data = W3, family = binomial)
model_tr_sci <- glm( hesitancy ~ tr_sci + sex + age + educ + reg + eco_insec,
data = W3, family = binomial)
model_pray <- glm( hesitancy ~ pray + sex + age + educ + reg + eco_insec,
data = W3, family = binomial)
model_media <- glm( hesitancy ~ media + sex + age + educ + reg + eco_insec,
data = W3, family = binomial)
model_low_comp <- glm( hesitancy ~ low_comp + sex + age + educ + reg + eco_insec,
data = W3, family = binomial)
model_distrust_gov <- glm( hesitancy ~ distrust_gov + sex + age + educ + reg + eco_insec,
data = W3, family = binomial)
model_distrust_inst <- glm( hesitancy ~ distrust_inst + sex + age + educ + reg + eco_insec,
data = W3, family = binomial)
#Additional model for final table
model_educ <- glm( hesitancy ~ educ + sex + age + reg + eco_insec,
data = W3, family = binomial)
#coeff
coeff_educ =  exp(extract_numeric(model_educ$coefficients[2]))
#significance
summary(model_educ)$coeff[-1,4] < 0.05
#Gathering coefficients
coeff = extract_numeric(model_vac_bad$coefficients[2])
coeff[2] = extract_numeric(model_vac_ob$coefficients[2])
coeff[3] = extract_numeric(model_worry$coefficients[2])
coeff[4] = extract_numeric(model_risk$coefficients[2])
coeff[5] = extract_numeric(model_conspiracy$coefficients[2])
coeff[6] = extract_numeric(model_nat$coefficients[2])
coeff[7] = extract_numeric(model_h_locus$coefficients[2])
coeff[8] = extract_numeric(model_he_eco$coefficients[2])
coeff[9] = extract_numeric(model_PTV_L$coefficients[2])
coeff[10] = extract_numeric(model_PTV_5SM$coefficients[2])
coeff[11] = extract_numeric(model_PTV_BOI$coefficients[2])
coeff[12] = extract_numeric(model_tr_sci$coefficients[2])
coeff[13] = extract_numeric(model_pray$coefficients[2])
coeff[14] = extract_numeric(model_media$coefficients[2])
coeff[15] = extract_numeric(model_low_comp$coefficients[2])
coeff[16] = extract_numeric(model_distrust_gov$coefficients[2])
coeff[17] = extract_numeric(model_distrust_inst$coefficients[2])
#Transform in odds ratio
coeff_exp = unlist(lapply(coeff, exp))
#Significance
summary(model_vac_bad)$coeff[-1,4] < 0.05
summary(model_vac_ob)$coeff[-1,4] < 0.05
summary(model_worry)$coeff[-1,4] < 0.05 #not significant
summary(model_risk)$coeff[-1,4] < 0.05
summary(model_conspiracy)$coeff[-1,4] < 0.05
summary(model_nat)$coeff[-1,4] < 0.05
summary(model_h_locus)$coeff[-1,4] < 0.05
summary(model_he_eco)$coeff[-1,4] < 0.05
summary(model_PTV_L)$coeff[-1,4] < 0.05
summary(model_PTV_5SM)$coeff[-1,4] < 0.05 #not significant
summary(model_PTV_BOI)$coeff[-1,4] < 0.05
summary(model_tr_sci)$coeff[-1,4] < 0.05
summary(model_pray)$coeff[-1,4] < 0.05 #not significant
summary(model_media)$coeff[-1,4] < 0.05 #not significant
summary(model_low_comp)$coeff[-1,4] < 0.05
summary(model_distrust_gov)$coeff[-1,4] < 0.05
summary(model_distrust_inst)$coeff[-1,4] < 0.05
#vector for significance
Significance = rep(c("Significant"),17)
Significance[3] = "Not significant"
Significance[10] = "Not significant"
Significance[13] = "Not significant"
Significance[14] = "Not significant"
#Gatering strength scores
strength = centMGM %>%
filter(measure=="Strength") %>%
select(value) %>%
filter(!row_number() %in% c(15:20))
#Gatering degree
degree_cent_graph = degree_cent[-c(15:20)]
#Gathering names
names = shortnames
names = names[-c(15:20)]
#Merging into a df1
scatterplot = data.frame(names, coeff_exp, strength, Significance) %>%
rename(strength = value)
scatterplot$names = as.factor(scatterplot$names)
scatterplot$coeff_exp = as.numeric(scatterplot$coeff_exp)
scatterplot$strength = as.numeric(scatterplot$strength)
scatterplot$Significance = as.factor(scatterplot$Significance)
#Merging into a df2
scatterplot_degree = data.frame(names, coeff_exp, degree_cent_graph, Significance)
scatterplot_degree$degree_cent_graph = as.numeric(scatterplot_degree$degree_cent_graph)
scatterplot_degree
#Strength
graph_strength = ggplot(scatterplot, aes(x=strength, y=coeff_exp, label = names)) +
geom_point((aes(color=Significance))) + theme_nice() +
geom_smooth(method=lm, se = FALSE, linetype = "dotted", color = "#DCDCDC") +
geom_text_repel(size = 3) +
xlab("Strength centrality") + ylab("Regression coefficient") +
scale_fill_discrete(labels=c('label1', 'label2'))
ggsave(here("Output", "graph_strength.jpg"), graph_strength, height = 5, width = 8)
#Strength
graph_strength = ggplot(scatterplot, aes(x=strength, y=coeff_exp, label = names)) +
geom_point((aes(color=Significance))) + theme_nice() +
geom_smooth(method=lm, se = FALSE, linetype = "dotted", color = "#DCDCDC") +
geom_text_repel(size = 3) +
xlab("Strength centrality") + ylab("Regression coefficient") +
scale_fill_discrete(labels=c('label1', 'label2'))
ggsave(here("Output", "graph_strength.jpg"), graph_strength, height = 5, width = 8)
#Degree
graph_degree = ggplot(scatterplot_degree, aes(x=degree_cent_graph, y=coeff_exp, label = names)) +
geom_point((aes(color=Significance))) + theme_nice() +
geom_smooth(method=lm, se = FALSE, linetype = "dotted", color = "#DCDCDC") +
geom_text_repel(size = 3) +
xlab("Degree centrality") + ylab("Regression coefficient") +
scale_fill_discrete(labels=c('label1', 'label2'))
ggsave(here("Output", "graph_degree.jpg"), graph_degree, height = 5, width = 8)
final_tab = scatterplot %>%
mutate(degree = scatterplot_degree$degree_cent_graph) %>%
add_row(names = "educ", coeff_exp = 1.764246, strength = 1.061313041,
Significance = "Significant", degree = 10) %>%
filter(names %in% c("vac_free","vac_bad","low_comp","conspiracy","nat","educ")) %>%
mutate(edge_weight=c(0.95, 0.34, 0.34, 0.12, 0.07, 0.07)) %>%
relocate(Significance, .after = edge_weight)
final_tab
#conversion of type
final_tab$names = as.factor(final_tab$names)
final_tab$coeff_exp = as.numeric(final_tab$coeff_exp)
final_tab$strength = as.numeric(final_tab$strength)
final_tab$degree = as.numeric(final_tab$degree)
final_tab$edge_weight = as.numeric(final_tab$edge_weight)
final_tab$Significance = as.factor(final_tab$Significance)
final_tab
final_tab_z = final_tab %>%
mutate(coeff_exp = (coeff_exp - mean(coeff_exp))/sd(coeff_exp),
strength = (strength - mean(strength))/sd(strength),
degree = (degree - mean(degree))/sd(degree),
edge_weight = (edge_weight - mean(edge_weight))/sd(edge_weight))
final_tab_z
#Z scores
final_tab_z = final_tab %>%
mutate(coeff_exp = (coeff_exp - mean(coeff_exp))/sd(coeff_exp),
strength = (strength - mean(strength))/sd(strength),
degree = (degree - mean(degree))/sd(degree),
edge_weight = (edge_weight - mean(edge_weight))/sd(edge_weight)) %>%
mutate_if(is.numeric, ~round(., 2))
final_tab_z
final_tab_z
#communities
saveRDS(CommunityStabTotal, here("Input", "CommunityStabTotal.rds"))
#bootnet
saveRDS(edgeacc, here("Input","edgeacc.rds"))
saveRDS(centstab, here("Input", "centstab.rds"))
#final tab
saveRDS(final_tab, here("Input", "final_tab.rds"))
saveRDS(final_tab_z, here("Input", "final_tab_z.rds"))
##only upper triangle without edge weigths 0 for readability
EdgeWeight_Total_half<-upper.triangle(inputGraphMGM)
EdgeWeight_Total_half[EdgeWeight_Total_half == 0] <- NA
EdgeWeightsExcel_half<- list("mgm" = EdgeWeight_Total_half)
write.xlsx(EdgeWeightsExcel_half, "../Output/EdgeWeightsExcel_half.xlsx",
colWidths = "auto", rowNames = TRUE)
#packages
library("pacman")
p_load(tidyverse, here, sjlabelled, stringr, glue, janitor, haven, stargazer,
ltm, skimr, readxl)
#remove scientific notation
options(scipen=999)
#Load database
response_original = read_rds(here("Input", "v1.0_ResPOnsE_COVID_19_W1-W4-2.rds"))  %>%
clean_names()
# 10 November to 22 December 2021
#Select and rename variables
W3 = response_original %>%
filter(info_wave==3) %>%
dplyr::select(c(v2,v3,j5_01,v1,f10,f3,f9,h1_04,j4bis_b,b2_03,b2_06,b2_07,d5,d1,
e4_bis,k3_03,k3_04,k3_05,e2_01,e2_04,j5_02,g7,c5,s1,s2,
s9,s8,c1)) %>%
mutate(across(v2:c1, ~replace(., .>97 , NA))) %>%
na.omit()
#colnames
colnames(W3) = c("vac","vac_int","vac_bad","vac_ob","worry","risk","conspiracy",
"nat","h_locus","comp_dist", "comp_mask","comp_hand","he_eco",
"judg_gov_covid","judg_gov","PTV_L","PTV_5SM","PTV_BOI","tr_par",
"tr_EU","tr_sci","pray","media","sex","age","educ",
"reg","eco_insec")
# W3 full to do ttest (next chunk)
W3_full = W3 %>%
mutate(hesitancy = case_when(
(vac_int < 3  | vac == 1)~ 0,
(vac_int > 2 & vac == 2)~ 1,))
#combine vac_int and vac in INT_VAC
W3 = W3 %>%
mutate(hesitancy = case_when(
(vac_int < 3  | vac == 1)~ 0,
(vac_int > 2 & vac == 2)~ 1,)) %>%
dplyr::select(-c(vac_int, vac))
#invert polarity and recode
W3 = W3 %>%
mutate((across(vac_bad,  ~ 6 - .)),
worry = ifelse(worry<=2, 1, 0),
conspiracy = ifelse(conspiracy<3, 1, 0),
pray = ifelse(pray<=4, 0, 1),
media = ifelse(media>=4 & media<=7, 1, 0),
sex = ifelse(sex==2, 1, 0),
educ = ifelse(educ<=5, 1, 0),
(across(age,  ~ 89 - .)),
reg = ifelse(reg<=3, 1, 0),
(across(comp_dist:comp_hand,  ~ 10 - .)),
(across(judg_gov_covid:judg_gov,  ~ 10 - .)),
(across(tr_par:tr_EU,  ~ 10- .)))
#Select and rename variables (no "na.omit")
W3_full_nolist = response_original %>%
filter(info_wave==3) %>%
dplyr::select(c(v2,v3,j5_01,v1,f10,f3,f9,h1_04,j4bis_b,b2_03,b2_06,b2_07,d5,d1,
e4_bis,k3_03,k3_04,k3_05,e2_01,e2_04,j5_02,g7,c5,s1,s2,
s9,s8,c1)) %>%
mutate(across(v2:c1, ~replace(., .>97 , NA)))
#colnames
colnames(W3_full_nolist) = c("vac","vac_int","vac_bad","vac_ob","worry","risk","conspiracy",
"nat","h_locus","comp_dist", "comp_mask","comp_hand","he_eco",
"judg_gov_covid","judg_gov","PTV_L","PTV_5SM","PTV_BOI","tr_par",
"tr_EU","tr_sci","pray","media","sex","age","educ",
"reg","eco_insec")
# W3_full_nolist full to do ttest (next section)
W3_full_nolist = W3_full_nolist %>%
mutate(hesitancy = case_when(
(vac_int < 3  | vac == 1)~ 0,
(vac_int > 2 & vac == 2)~ 1,))
#invert polarity and recode
W3_full_nolist = W3_full_nolist %>%
mutate((across(vac_bad,  ~ 6 - .)),
worry = ifelse(worry<=2, 1, 0),
conspiracy = ifelse(conspiracy<3, 1, 0),
pray = ifelse(pray<=4, 0, 1),
media = ifelse(media>=4 & media<=7, 1, 0),
sex = ifelse(sex==2, 1, 0),
educ = ifelse(educ<=5, 1, 0),
(across(age,  ~ 89 - .)),
reg = ifelse(reg<=3, 1, 0),
(across(comp_dist:comp_hand,  ~ 10 - .)),
(across(judg_gov_covid:judg_gov,  ~ 10 - .)),
(across(tr_par:tr_EU,  ~ 10- .)))
# I had 9325 before listwise, 1535 after. It means I m working with 16,46% of
# the sample. Hence, I ll do t test full sample vs restricted one.
#Load valid cases spreadshit (avaiable at: https://dataverse.unimi.it/dataset.xhtml?persistentId=doi:10.13130/RD_UNIMI/FF0ABQ)
valid = read_excel(here("Input", "Valid_cases.xlsx"))
#Select V I used in the analysis to retrieve true number of N
valid = valid %>%
dplyr::select(c(v2,v3,j5_01,v1,f10,f3,f9,h1_04,j4bis_b,b2_03,b2_06,b2_07,d5,d1,
e4_bis,k3_03,k3_04,k3_05,e2_01,e2_04,j5_02,g7,c5,s1,s2,
s9,s8,c1))
#Extract miniumu number of obs per question
min(valid)
# TRUE N = 3767. Thus I had 3767 before listwise, 1535 after. It means I m working with 40.7% of
# the sample.
##OLD
#loop each V and run t.test
tests_list_old <- lapply(seq_along(W3_full), function(i){
t.test(W3_full[[i]], W3_full_nolist[[i]])
})
pvalues_old = as.data.frame(sapply(tests_list_old, '[[', 'p.value'))
#print true when the means differ
pvalues_old[,2] = names(W3_full)
pvalues_old[,3] = with(pvalues_old,pvalues_old<0.05/29)
##NEW
#loop each V and run t.test
tests_list <- lapply(seq_along(W3_full), function(i){
t.test(W3_full[[i]], W3_full_nolist[[i]])
})
means = sapply(tests_list, '[[', 'estimate')
dif_mean = means[1,] - means[2,]
pvalues = as.data.frame(sapply(tests_list, '[[', 'p.value'))
#print true when the means differ
pvalues = pvalues %>%
rename(pvalues = "sapply(tests_list, \"[[\", \"p.value\")") %>%
bind_cols(names(W3_full))
mult_test = 0.05/nrow(pvalues)
pvalues_response = pvalues %>%
rename(variable = "...2")  %>%
bind_cols(dif_mean) %>%
filter(pvalues<mult_test) %>%
rename(dif_mean = "...3")
pvalues_response = pvalues_response %>%
dplyr::select(variable, dif_mean, pvalues)
pvalues_response = pvalues_response %>%
dplyr::select(variable, dif_mean, pvalues)
pvalues_response
pvalues
pvalues_response
pvalues_response = pvalues_response %>%
dplyr::select(variable, dif_mean, pvalues) %>%
mutate_if(is.numeric, ~round(., 2))
pvalues_response
pvalues_response = pvalues_response %>%
dplyr::select(variable, dif_mean, pvalues) %>%
mutate_if(is.numeric, ~round(., 4))
pvalues_response
pvalues_response = pvalues_response %>%
dplyr::select(variable, dif_mean, pvalues) %>%
mutate_if(is.numeric, ~round(., 2))
pvalues_response
#packages
library("pacman")
p_load(tidyverse, here, sjlabelled, stringr, glue, janitor, haven, stargazer,
ltm, skimr, readxl)
#remove scientific notation
options(scipen=999)
#Load database
response_original = read_rds(here("Input", "v1.0_ResPOnsE_COVID_19_W1-W4-2.rds"))  %>%
clean_names()
# 10 November to 22 December 2021
#Select and rename variables
W3 = response_original %>%
filter(info_wave==3) %>%
dplyr::select(c(v2,v3,j5_01,v1,f10,f3,f9,h1_04,j4bis_b,b2_03,b2_06,b2_07,d5,d1,
e4_bis,k3_03,k3_04,k3_05,e2_01,e2_04,j5_02,g7,c5,s1,s2,
s9,s8,c1)) %>%
mutate(across(v2:c1, ~replace(., .>97 , NA))) %>%
na.omit()
#colnames
colnames(W3) = c("vac","vac_int","vac_bad","vac_ob","worry","risk","conspiracy",
"nat","h_locus","comp_dist", "comp_mask","comp_hand","he_eco",
"judg_gov_covid","judg_gov","PTV_L","PTV_5SM","PTV_BOI","tr_par",
"tr_EU","tr_sci","pray","media","sex","age","educ",
"reg","eco_insec")
# W3 full to do ttest (next chunk)
W3_full = W3 %>%
mutate(hesitancy = case_when(
(vac_int < 3  | vac == 1)~ 0,
(vac_int > 2 & vac == 2)~ 1,))
#combine vac_int and vac in INT_VAC
W3 = W3 %>%
mutate(hesitancy = case_when(
(vac_int < 3  | vac == 1)~ 0,
(vac_int > 2 & vac == 2)~ 1,)) %>%
dplyr::select(-c(vac_int, vac))
#invert polarity and recode
W3 = W3 %>%
mutate((across(vac_bad,  ~ 6 - .)),
worry = ifelse(worry<=2, 1, 0),
conspiracy = ifelse(conspiracy<3, 1, 0),
pray = ifelse(pray<=4, 0, 1),
media = ifelse(media>=4 & media<=7, 1, 0),
sex = ifelse(sex==2, 1, 0),
educ = ifelse(educ<=5, 1, 0),
(across(age,  ~ 89 - .)),
reg = ifelse(reg<=3, 1, 0),
(across(comp_dist:comp_hand,  ~ 10 - .)),
(across(judg_gov_covid:judg_gov,  ~ 10 - .)),
(across(tr_par:tr_EU,  ~ 10- .)))
#Select and rename variables (no "na.omit")
W3_full_nolist = response_original %>%
filter(info_wave==3) %>%
dplyr::select(c(v2,v3,j5_01,v1,f10,f3,f9,h1_04,j4bis_b,b2_03,b2_06,b2_07,d5,d1,
e4_bis,k3_03,k3_04,k3_05,e2_01,e2_04,j5_02,g7,c5,s1,s2,
s9,s8,c1)) %>%
mutate(across(v2:c1, ~replace(., .>97 , NA)))
#colnames
colnames(W3_full_nolist) = c("vac","vac_int","vac_bad","vac_ob","worry","risk","conspiracy",
"nat","h_locus","comp_dist", "comp_mask","comp_hand","he_eco",
"judg_gov_covid","judg_gov","PTV_L","PTV_5SM","PTV_BOI","tr_par",
"tr_EU","tr_sci","pray","media","sex","age","educ",
"reg","eco_insec")
# W3_full_nolist full to do ttest (next section)
W3_full_nolist = W3_full_nolist %>%
mutate(hesitancy = case_when(
(vac_int < 3  | vac == 1)~ 0,
(vac_int > 2 & vac == 2)~ 1,))
#invert polarity and recode
W3_full_nolist = W3_full_nolist %>%
mutate((across(vac_bad,  ~ 6 - .)),
worry = ifelse(worry<=2, 1, 0),
conspiracy = ifelse(conspiracy<3, 1, 0),
pray = ifelse(pray<=4, 0, 1),
media = ifelse(media>=4 & media<=7, 1, 0),
sex = ifelse(sex==2, 1, 0),
educ = ifelse(educ<=5, 1, 0),
(across(age,  ~ 89 - .)),
reg = ifelse(reg<=3, 1, 0),
(across(comp_dist:comp_hand,  ~ 10 - .)),
(across(judg_gov_covid:judg_gov,  ~ 10 - .)),
(across(tr_par:tr_EU,  ~ 10- .)))
# I had 9325 before listwise, 1535 after. It means I m working with 16,46% of
# the sample. Hence, I ll do t test full sample vs restricted one.
#Load valid cases spreadshit (avaiable at: https://dataverse.unimi.it/dataset.xhtml?persistentId=doi:10.13130/RD_UNIMI/FF0ABQ)
valid = read_excel(here("Input", "Valid_cases.xlsx"))
#Select V I used in the analysis to retrieve true number of N
valid = valid %>%
dplyr::select(c(v2,v3,j5_01,v1,f10,f3,f9,h1_04,j4bis_b,b2_03,b2_06,b2_07,d5,d1,
e4_bis,k3_03,k3_04,k3_05,e2_01,e2_04,j5_02,g7,c5,s1,s2,
s9,s8,c1))
#Extract miniumu number of obs per question
min(valid)
# TRUE N = 3767. Thus I had 3767 before listwise, 1535 after. It means I m working with 40.7% of
# the sample.
tests_list_old <- lapply(seq_along(W3_full), function(i){
t.test(W3_full[[i]], W3_full_nolist[[i]])
tests_list_old
tests_list_old <- lapply(seq_along(W3_full), function(i){
t.test(W3_full[[i]], W3_full_nolist[[i]])
})
tests_list_old
pvalues_old = as.data.frame(sapply(tests_list_old, '[[', 'p.value'))
pvalues_old
pvalues_old[,2] = names(W3_full)
pvalues_old[,3] = with(pvalues_old,pvalues_old<0.05/29)
pvalues_old
